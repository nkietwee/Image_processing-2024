{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab 1.1 Image Representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import mpl_toolkits\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Image Color Order with different libraries**\n",
    "In this part, you will explore how different libraries interpret and display image colors. Specifically, you will compare Matplotlib and OpenCV libraries for image loading and display.\n",
    "\n",
    "**Load and Display Images:**\n",
    "   - Load an image using both Matplotlib `plt.imread()` and OpenCV `cv2.imread()` libraries.\n",
    "   - Display the images side by side using Matplotlib.\n",
    "\n",
    "**HINT** : `plt.imread()`,`cv2.imread()`,`fig, axs = plt.subplots(1, 2)`\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/image_processing-2024/master/Lab1_image-representation/asset/1-1.png)\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of rows must be a positive integer, not './asset/1-1.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m mpl_img \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mimread(path)\n\u001b[0;32m      4\u001b[0m cv_img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path)\n\u001b[1;32m----> 6\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:1475\u001b[0m, in \u001b[0;36msubplots\u001b[1;34m(nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;124;03mCreate a figure and a set of subplots.\u001b[39;00m\n\u001b[0;32m   1333\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1472\u001b[0m \n\u001b[0;32m   1473\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1474\u001b[0m fig \u001b[38;5;241m=\u001b[39m figure(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfig_kw)\n\u001b[1;32m-> 1475\u001b[0m axs \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1476\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubplot_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubplot_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1477\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mgridspec_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgridspec_kw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1478\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fig, axs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py:891\u001b[0m, in \u001b[0;36mFigureBase.subplots\u001b[1;34m(self, nrows, ncols, sharex, sharey, squeeze, width_ratios, height_ratios, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth_ratios\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must not be defined both as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter and as key in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgridspec_kw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    889\u001b[0m     gridspec_kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth_ratios\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m width_ratios\n\u001b[1;32m--> 891\u001b[0m gs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_gridspec(nrows, ncols, figure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgridspec_kw)\n\u001b[0;32m    892\u001b[0m axs \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39msubplots(sharex\u001b[38;5;241m=\u001b[39msharex, sharey\u001b[38;5;241m=\u001b[39msharey, squeeze\u001b[38;5;241m=\u001b[39msqueeze,\n\u001b[0;32m    893\u001b[0m                   subplot_kw\u001b[38;5;241m=\u001b[39msubplot_kw)\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m axs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py:1514\u001b[0m, in \u001b[0;36mFigureBase.add_gridspec\u001b[1;34m(self, nrows, ncols, **kwargs)\u001b[0m\n\u001b[0;32m   1475\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;124;03mReturn a `.GridSpec` that has this figure as a parent.  This allows\u001b[39;00m\n\u001b[0;32m   1477\u001b[0m \u001b[38;5;124;03mcomplex layout of Axes in the figure.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1510\u001b[0m \n\u001b[0;32m   1511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# pop in case user has added this...\u001b[39;00m\n\u001b[1;32m-> 1514\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSpec(nrows\u001b[38;5;241m=\u001b[39mnrows, ncols\u001b[38;5;241m=\u001b[39mncols, figure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\gridspec.py:379\u001b[0m, in \u001b[0;36mGridSpec.__init__\u001b[1;34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhspace \u001b[38;5;241m=\u001b[39m hspace\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure \u001b[38;5;241m=\u001b[39m figure\n\u001b[1;32m--> 379\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight_ratios\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\gridspec.py:49\u001b[0m, in \u001b[0;36mGridSpecBase.__init__\u001b[1;34m(self, nrows, ncols, height_ratios, width_ratios)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m----------\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m    If not given, all rows will have the same height.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(nrows, Integral) \u001b[38;5;129;01mor\u001b[39;00m nrows \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of rows must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnrows\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ncols, Integral) \u001b[38;5;129;01mor\u001b[39;00m ncols \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of columns must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mncols\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of rows must be a positive integer, not './asset/1-1.png'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### START CODE HERE ###\n",
    "path = \"./asset/1-1.png\"\n",
    "mpl_img = plt.imread(path)\n",
    "cv_img = cv2.imread(path)\n",
    "\n",
    "fig, axs = plt.subplots(path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Opencv [BGR] vs Matplotlib [RGB]\n",
    "Examine the grayscale representations of individual color channels for each library.\n",
    "***PLEASE use direct slicing method***\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image.png](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/image_processing-2024/master/Lab1_image-representation/asset/1-2.png)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "fig, axs = plt.subplots(None)\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Opencv BGR -> RGB\n",
    "Compare the images displayed after conversion using both methods (`cv2.cvtColor()` and `direct slicing`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `cv2.cvtColor()`\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image-3.png](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/image_processing-2024/master/Lab1_image-representation/asset/1-3.png)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `direct slicing method (array[...])`\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image-3.png](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/image_processing-2024/master/Lab1_image-representation/asset/1-4.png)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Image Reshape**\n",
    "\n",
    "Implement the code to tranform the image from ***channels last (HWC) to channels first (CHW)***.<br>\n",
    "\n",
    "**NumPy Transpose**<br>\n",
    "Compare the difference between :\n",
    "- `np.transpose(<img>)`\n",
    "- `np.transpose(<img>,(2,0,1))`\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "- The image display only the Red channel.\n",
    "\n",
    "```\n",
    "np.transpose(mpl_img) => Before : (3265, 4898, 3) | After : (3, 4898, 3265)\n",
    "np.transpose(mpl_img,(2,0,1)) => Before : (3265, 4898, 3) | After : (3, 3265, 4898)\n",
    "```\n",
    "\n",
    "![image.png](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/image_processing-2024/master/Lab1_image-representation/asset/1-5.png)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "reshaped_trade_trans = np.transpose(None)\n",
    "print('np.transpose(mpl_img) => Before :',mpl_img.shape,'| After :',reshaped_trade_trans.shape)\n",
    "\n",
    "\n",
    "reshaped_trans = np.transpose(None)\n",
    "print('np.transpose(mpl_img,(2,0,1)) => Before :',mpl_img.shape,'| After :',reshaped_trans.shape)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you code work properly, the cell below should run without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert reshaped_trade_trans.shape == (mpl_img.shape[2], mpl_img.shape[1], mpl_img.shape[0]), \\\n",
    "    f\"Error: Shape mismatch after traditional transpose. Expected {(mpl_img.shape[1], mpl_img.shape[0], mpl_img.shape[2])}, got {reshaped_trade_trans.shape}\"\n",
    "print(\"Assertion for traditional transpose passed successfully.\")\n",
    "\n",
    "assert reshaped_trans.shape == (mpl_img.shape[2], mpl_img.shape[0], mpl_img.shape[1]), \\\n",
    "    f\"Error: Shape mismatch after specified transpose. Expected {(mpl_img.shape[2], mpl_img.shape[0], mpl_img.shape[1])}, got {reshaped_trans.shape}\"\n",
    "print(\"Assertion for specified transpose passed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NumPy Reshape**\n",
    "\n",
    "Use `np.reshape()`. Ensure the new shape is (3, height, width).\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "- The image display only the Red channel.\n",
    "\n",
    "```\n",
    "Before : (3265, 4898, 3) | After : (3, 3265, 4898)\n",
    "```\n",
    "\n",
    "![image.png](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/image_processing-2024/master/Lab1_image-representation/asset/1-6.png)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "reshaped_reshape = np.reshape(None)\n",
    "print('Before :',mpl_img.shape,'| After :',reshaped_reshape.shape)\n",
    "\n",
    "fig, axs = plt.subplots(None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you code work properly, the cell below should run without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert reshaped_reshape.shape == (mpl_img.shape[2], mpl_img.shape[0], mpl_img.shape[1]), \\\n",
    "    f\"Error: Shape mismatch after reshape. Expected {(mpl_img.shape[2], mpl_img.shape[0], mpl_img.shape[1])}, got {reshaped_reshape.shape}\"\n",
    "print(\"Assertion for reshape passed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NumPy moveaxis**\n",
    "\n",
    "Use `np.moveaxis` to move the channels axis from the last position to the first.\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "- The image display only the Red channel.\n",
    "\n",
    "```\n",
    "Before : (3265, 4898, 3) | After : (3, 3265, 4898)\n",
    "```\n",
    "\n",
    "![image.png](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/image_processing-2024/master/Lab1_image-representation/asset/1-7.png)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "reshaped_mvx = np.moveaxis(None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you code work properly, the cell below should run without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert reshaped_mvx.shape == (mpl_img.shape[2], mpl_img.shape[0], mpl_img.shape[1]), \\\n",
    "    f\"Error: Shape mismatch after np.moveaxis. Expected {(mpl_img.shape[2], mpl_img.shape[0], mpl_img.shape[1])}, got {reshaped_mvx.shape}\"\n",
    "print(\"Assertion for np.moveaxis passed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reduce Bit Depth using Quantization**\n",
    "In this part, you will explore how to reduce the bit depth of an image using quantization. Quantization is a technique used to map pixel values from a continuous range to a smaller set of discrete values, effectively reducing the number of bits used to represent each pixel.\n",
    "$$\n",
    "\\begin{align*}\n",
    "Q_{level} &= 2^{bit dept-1}\\\\\n",
    "Q &= floor(NormValue(S_i) * Q_{level})\\\\\n",
    "Q &= floor((\\frac{S_i-S_{min}}{S_{max}-S_{min}})*Q_{level})\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Please complete the function below.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![image.png](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/image_processing-2024/master/Lab1_image-representation/asset/1-8.png)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "def quantize(img,bit_dept):\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "gray_img = cv2.cvtColor(cv_img, cv2.COLOR_RGB2GRAY)\n",
    "bd8 = quantize(None)\n",
    "bd4 = quantize(None)\n",
    "\n",
    "fig, axs = plt.subplots(None)\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you code work properly, the cell below should run without error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value_bd8 = 2**8 - 1\n",
    "max_value_bd4 = 2**4 - 1\n",
    "\n",
    "assert np.min(bd8) >= 0 and np.max(bd8) <= max_value_bd8, \\\n",
    "    f\"Error: Values in bd8 are out of expected range 0-{max_value_bd8}. Got min={np.min(bd8)}, max={np.max(bd8)}\"\n",
    "assert np.min(bd4) >= 0 and np.max(bd4) <= max_value_bd4, \\\n",
    "    f\"Error: Values in bd4 are out of expected range 0-{max_value_bd4}. Got min={np.min(bd4)}, max={np.max(bd4)}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3D Image Surface**\n",
    "\n",
    "use `plot_surface()` to plot the image in 3D space, where the z-axis represents the normalized pixel intensity values.\n",
    "\n",
    "<details>\n",
    "\n",
    "<summary>\n",
    "<font size=\"3\" color=\"orange\">\n",
    "<b>Expected output</b>\n",
    "</font>\n",
    "</summary>\n",
    "\n",
    "- The output should resemble this, but not be identical\n",
    "\n",
    "![3d-surface.gif](https://raw.githubusercontent.com/Digital-Image-Processing-Laboratory/image_processing-2024/master/Lab1_image-representation/asset/3d-surface.gif)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl \n",
    "### START CODE HERE ###\n",
    "cv_img_gray = cv2.cvtColor(None)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "\n",
    "ax.plot_surface(None)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "### END CODE HERE ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Question**\n",
    "1. How to perform manual color conversion (using only array slicing) of image array read from openCV (BGR) to RGB?\n",
    "2. How to perform manual conversion (using only array slicing) of image array from channel last to channel first?\n",
    "3. Why does np.reshape destroy the image integrity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
